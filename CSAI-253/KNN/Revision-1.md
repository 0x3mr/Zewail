### Question 1:
*What is the primary goal of machine learning?*

   A. To create hand-crafted rules for decision-making  
   B. To learn patterns from data and exploit them  
   C. To replace human experts in all fields  
   D. To memorize training data perfectly  

<details>
<summary>Answer</summary>
B. To learn patterns from data and exploit them
</details>

---

### Question 2:
*Which of the following is NOT a real-world application of machine learning?*

   A. Spam filtering  
   B. Object recognition  
   C. Handwriting recognition  
   D. Manual data entry  

<details>
<summary>Answer</summary>
D. Manual data entry
</details>

---

### Question 3:
*What is the main difference between supervised and unsupervised learning?*

   A. Supervised learning uses labeled data, while unsupervised learning uses unlabeled data  
   B. Supervised learning uses unlabeled data, while unsupervised learning uses labeled data  
   C. Supervised learning is used for regression, while unsupervised learning is used for classification  
   D. Supervised learning is used for clustering, while unsupervised learning is used for prediction  

<details>
<summary>Answer</summary>
A. Supervised learning uses labeled data, while unsupervised learning uses unlabeled data
</details>

---

### Question 4:
*Which of the following is an example of supervised learning?*

   A. Grouping news stories automatically  
   B. Predicting house prices  
   C. Clustering customer data  
   D. Finding patterns in unlabeled data  

<details>
<summary>Answer</summary>
B. Predicting house prices
</details>

---

### Question 5:
*What is the primary goal of reinforcement learning?*

   A. To learn patterns from labeled data  
   B. To find clusters in unlabeled data  
   C. To learn a policy that maximizes the agent's reward  
   D. To minimize the error in regression tasks  

<details>
<summary>Answer</summary>
C. To learn a policy that maximizes the agent's reward
</details>

---

### Question 6:
*Which of the following is a challenge in supervised learning?*

   A. Labeling data is expensive  
   B. Unlabeled data is difficult to obtain  
   C. Reinforcement learning is not applicable  
   D. Clustering is not possible  

<details>
<summary>Answer</summary>
A. Labeling data is expensive
</details>

---

### Question 7:
*What is the main difference between classification and regression tasks?*

   A. Classification predicts discrete labels, while regression predicts continuous values  
   B. Classification predicts continuous values, while regression predicts discrete labels  
   C. Classification is used for clustering, while regression is used for prediction  
   D. Classification is unsupervised, while regression is supervised  

<details>
<summary>Answer</summary>
A. Classification predicts discrete labels, while regression predicts continuous values
</details>

---

### Question 8:
*Which of the following is an example of a binary classification problem?*

   A. Predicting house prices  
   B. Classifying emails as spam or not spam  
   C. Grouping customers into clusters  
   D. Predicting the weather  

<details>
<summary>Answer</summary>
B. Classifying emails as spam or not spam
</details>

---

### Question 9:
*What is the main goal of data preparation in the machine learning workflow?*

   A. To collect as much data as possible  
   B. To clean and normalize the data for better model performance  
   C. To label all the data manually  
   D. To reduce the number of features in the dataset  

<details>
<summary>Answer</summary>
B. To clean and normalize the data for better model performance
</details>

---

### Question 10:
*Which of the following is NOT a step in the machine learning workflow?*

   A. Data collection  
   B. Model selection  
   C. Data labeling  
   D. Model evaluation  

<details>
<summary>Answer</summary>
C. Data labeling
</details>

---

### Question 11:
*What is the primary purpose of model selection in the machine learning workflow?*

   A. To collect more data  
   B. To choose the best algorithm for the problem  
   C. To clean the data  
   D. To evaluate the model's performance  

<details>
<summary>Answer</summary>
B. To choose the best algorithm for the problem
</details>

---

### Question 12:
*Which of the following is a common issue in machine learning models?*

   A. Overfitting and underfitting  
   B. Data collection errors  
   C. Lack of computational power  
   D. Insufficient data labeling  

<details>
<summary>Answer</summary>
A. Overfitting and underfitting
</details>

---

### Question 13:
*What is overfitting in machine learning?*

   A. When the model is too simple and cannot capture the underlying patterns  
   B. When the model is too complex and learns the noise in the training data  
   C. When the model performs well on training data but poorly on unseen data  
   D. Both B and C  

<details>
<summary>Answer</summary>
D. Both B and C
</details>

---

### Question 14:
*What is underfitting in machine learning?*

   A. When the model is too complex and learns the noise in the training data  
   B. When the model is too simple and cannot capture the underlying patterns  
   C. When the model performs well on unseen data but poorly on training data  
   D. When the model has too many features  

<details>
<summary>Answer</summary>
B. When the model is too simple and cannot capture the underlying patterns
</details>

---

### Question 15:
*Which of the following is a way to reduce overfitting?*

   A. Increase the complexity of the model  
   B. Use more training data  
   C. Reduce the number of features  
   D. Both B and C  

<details>
<summary>Answer</summary>
D. Both B and C
</details>

---

### Question 16:
*What is the relationship between bias and variance in machine learning?*

   A. High bias leads to underfitting, while high variance leads to overfitting  
   B. High bias leads to overfitting, while high variance leads to underfitting  
   C. Low bias leads to underfitting, while low variance leads to overfitting  
   D. Low bias leads to overfitting, while low variance leads to underfitting  

<details>
<summary>Answer</summary>
A. High bias leads to underfitting, while high variance leads to overfitting
</details>

---

### Question 17:
*What is the K-Nearest Neighbors (K-NN) algorithm used for?*

   A. Clustering  
   B. Classification and regression  
   C. Reinforcement learning  
   D. Dimensionality reduction  

<details>
<summary>Answer</summary>
B. Classification and regression
</details>

---

### Question 18:
*How does the K-NN algorithm make predictions?*

   A. By learning an explicit mapping from the training data  
   B. By storing all training data and finding the K nearest neighbors at test time  
   C. By clustering the data into K groups  
   D. By reducing the dimensionality of the data  

<details>
<summary>Answer</summary>
B. By storing all training data and finding the K nearest neighbors at test time
</details>

---

### Question 19:
*Which of the following is a parameter of the K-NN algorithm?*

   A. The number of clusters (K)  
   B. The number of neighbors (K)  
   C. The learning rate  
   D. The regularization parameter  

<details>
<summary>Answer</summary>
B. The number of neighbors (K)
</details>

---

### Question 20:
*What is the most commonly used distance metric in K-NN for continuous numerical data?*

   A. Manhattan distance  
   B. Euclidean distance  
   C. Hamming distance  
   D. Cosine similarity  

<details>
<summary>Answer</summary>
B. Euclidean distance
</details>

---

### Question 21:
*Which of the following distance metrics is suitable for categorical or binary data?*

   A. Euclidean distance  
   B. Manhattan distance  
   C. Hamming distance  
   D. Cosine similarity  

<details>
<summary>Answer</summary>
C. Hamming distance
</details>

---

### Question 22:
*What is the main disadvantage of the K-NN algorithm?*

   A. It requires a large amount of memory to store all training data  
   B. It is not suitable for classification tasks  
   C. It cannot handle high-dimensional data  
   D. It is only applicable to regression tasks  

<details>
<summary>Answer</summary>
A. It requires a large amount of memory to store all training data
</details>

---

### Question 23:
*What happens if the value of K in K-NN is too small?*

   A. The model may overfit the data  
   B. The model may underfit the data  
   C. The model will perform well on unseen data  
   D. The model will have high bias  

<details>
<summary>Answer</summary>
A. The model may overfit the data
</details>

---

### Question 24:
*What happens if the value of K in K-NN is too large?*

   A. The model may overfit the data  
   B. The model may underfit the data  
   C. The model will perform well on unseen data  
   D. The model will have low bias  

<details>
<summary>Answer</summary>
B. The model may underfit the data
</details>

---

### Question 25:
*Which of the following is a way to choose the optimal value of K in K-NN?*

   A. Use cross-validation  
   B. Use a fixed value of K for all datasets  
   C. Use the smallest possible value of K  
   D. Use the largest possible value of K  

<details>
<summary>Answer</summary>
A. Use cross-validation
</details>

---

### Question 26:
*What is the main advantage of the K-NN algorithm?*

   A. It is simple and intuitive  
   B. It requires minimal memory  
   C. It is not sensitive to noisy features  
   D. It performs well in high-dimensional data  

<details>
<summary>Answer</summary>
A. It is simple and intuitive
</details>

---

### Question 27:
*Which of the following is a disadvantage of the K-NN algorithm?*

   A. It is computationally expensive at test time  
   B. It cannot handle categorical data  
   C. It is not suitable for regression tasks  
   D. It requires labeled data for training  

<details>
<summary>Answer</summary>
A. It is computationally expensive at test time
</details>

---

### Question 28:
*What is the effect of feature normalization on the K-NN algorithm?*

   A. It reduces the computational cost  
   B. It ensures that all features are on the same scale  
   C. It increases the model's complexity  
   D. It reduces the number of neighbors (K)  

<details>
<summary>Answer</summary>
B. It ensures that all features are on the same scale
</details>

---

### Question 29:
*Which of the following is true about the K-NN algorithm?*

   A. It learns an explicit mapping from the training data  
   B. It is a parametric method  
   C. It is a non-parametric method  
   D. It is only used for classification tasks  

<details>
<summary>Answer</summary>
C. It is a non-parametric method
</details>

---

### Question 30:
*What is the main reason for using cross-validation in K-NN?*

   A. To reduce the computational cost  
   B. To choose the optimal value of K  
   C. To normalize the features  
   D. To reduce the memory usage  

<details>
<summary>Answer</summary>
B. To choose the optimal value of K
</details>

---